import cv2
import numpy as np
import time
import beepy
import threading


start_time = time.time()

def draw_roi(frame, vertices, color=(255, 255, 0), fill_color=(50, 50, 50), alpha=0.3):
    overlay = frame.copy()

    # Draw the filled trapezium
    cv2.fillPoly(overlay, [vertices], fill_color)

    # Draw the trapezium lines
    cv2.polylines(overlay, [vertices], isClosed=True, color=color, thickness=2)

    # Blend the overlay with the frame
    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)


def inside_roi(point, vertices):
    return cv2.pointPolygonTest(vertices, point, False) >= 0

def bb_intersection_over_union(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])
    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])

    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)
    boxAArea = boxA[2] * boxA[3]
    boxBArea = boxB[2] * boxB[3]

    iou = interArea / float(boxAArea + boxBArea - interArea)
    return iou

def overlap_area(box, trapezoid_vertices):
    box_mask = np.zeros((height, width), dtype=np.uint8)
    trapezoid_mask = np.zeros((height, width), dtype=np.uint8)

    cv2.rectangle(box_mask, (box[0], box[1]), (box[0] + box[2], box[1] + box[3]), 255, -1)
    cv2.fillConvexPoly(trapezoid_mask, trapezoid_vertices, 255)

    intersection = np.logical_and(box_mask, trapezoid_mask)
    return np.sum(intersection)

def point_line_distance(point, line_start, line_end):
    num = abs((line_end[1] - line_start[1]) * point[0] - (line_end[0] - line_start[0]) * point[1] + line_end[0] * line_start[1] - line_end[1] * line_start[0])
    den = np.sqrt((line_end[1] - line_start[1])**2 + (line_end[0] - line_start[0])**2)
    return num / den

def play_beep():
    beepy.beep(sound=1)



    cv2.putText(frame, "Proximity Levels:", (10, height - 60), font, 0.6, text_color, 1)
    cv2.putText(frame, "High", (10, height - 30), font, 0.6, (0, 0, 255), 1)

def proximity_alert_bottom_edge(point, vertices, threshold):
    line_start, line_end = vertices[0], vertices[1]
    return point_line_distance(point, line_start, line_end) <= threshold

def proximity_alert_level(center, car_box, high_proximity_vertices, low_proximity_vertices):
    bottom_center = (center[0], car_box[1] + car_box[3])
    if inside_roi(bottom_center, high_proximity_vertices):
        return 'High'
    elif inside_roi(bottom_center, low_proximity_vertices):
        return 'Low'
    return None





# Load YOLOv4
net = cv2.dnn.readNet("/Users/humaid/Documents/Major Project/Proximity-alert-master/Proximity_YOLO_V4/yolov4-tiny.weights", "/Users/humaid/Documents/Major Project/Proximity-alert-master/Proximity_YOLO_V4/yolov4-tiny.cfg") 
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)

layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]


# Load COCO classes
with open("/Users/humaid/Documents/Major Project/Proximity-alert-master/Proximity_YOLO_V4/coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Video input
video = cv2.VideoCapture('Beat_white.mp4') # Try different indices like 2, 3, etc., if it doesn't work
_, frame = video.read()
height, width, _ = frame.shape

# Define the codec and create VideoWriter object

fourcc = cv2.VideoWriter_fourcc(*'XVID')
output_video = cv2.VideoWriter('output_video.avi', fourcc, 30.0, (width, height))




cv2.namedWindow("Proximity Alert System", cv2.WINDOW_NORMAL)
# Trapezium ROI coordinates
bottom_left = [0, int(height * 0.98)]  # Change height value
top_left = [int(width * 0.40), int(height * 0.50)]  # Change height value
bottom_right = [width, int(height * 0.98)]  # Change height value
top_right = [int(width * 0.60), int(height * 0.50)]  # Change height value

roi_vertices = np.array([bottom_left, bottom_right, top_right, top_left], dtype=np.int32)


high_proximity_zone = [bottom_left, bottom_right, (bottom_right[0], top_right[1]), (bottom_left[0], top_left[1])]
low_proximity_zone = [top_left, top_right, (top_right[0], bottom_right[1]), (top_left[0], bottom_left[1])]

high_proximity_zone = np.array(high_proximity_zone, dtype=np.int32)
low_proximity_zone = np.array(low_proximity_zone, dtype=np.int32)



# Proximity alert threshold
threshold = 50

while True:
    _, frame = video.read()
    if not _:
        break

    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    net.setInput(blob)
    outs = net.forward(output_layers)

    class_ids = []
    confidences = []
    boxes = []

    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:
                # Object detected
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                # Rectangle coordinates
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Non-max suppression
    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    # Draw the trapezoids
    middle_left = ((top_left[0] + bottom_left[0]) // 2, (top_left[1] + bottom_left[1]) // 2)
    middle_right = ((top_right[0] + bottom_right[0]) // 2, (top_right[1] + bottom_right[1]) // 2)

    low_proximity_vertices = np.array([middle_left, middle_right, top_right, top_left], dtype=np.int32)
    high_proximity_vertices = np.array([bottom_left, bottom_right, middle_right, middle_left], dtype=np.int32)

    draw_roi(frame, low_proximity_vertices, color=(51, 255, 51))  # Light green
    draw_roi(frame, high_proximity_vertices, color=(255, 102, 102))  # Light red

    # Draw detected cars and proximity alert message
    high_proximity_flag = False  # Add a flag for High Proximity
    low_proximity_flag = False
    for i in range(len(boxes)):
        if i in indexes:
            x, y, w, h = boxes[i]
            label = str(classes[class_ids[i]])
            if label in ['car', 'bicycle', 'motorbike', 'person']:
                color = (0, 255, 0) if label == 'car' else (255, 0, 0)  # Green for cars, blue for bicycles and persons
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
                cv2.putText(frame, f"{label}", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                center = (int(x + w / 2), int(y + h / 2))
                

                if inside_roi(center, roi_vertices):
                    # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                    car_box = [x, y, w, h]

                    

                    proximity_level = proximity_alert_level(center, car_box, high_proximity_vertices, low_proximity_vertices)

                    if proximity_level == 'High':
                        high_proximity_flag = True
                    elif proximity_level == 'Low':
                        low_proximity_flag = True


                    
                    cv2.putText(frame, f"{proximity_level} Proximity", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

                        
    
     # Change the trapezium color to red if High Proximity prompt is visible
    if high_proximity_flag:
        cv2.putText(frame, "High Proximity", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        
        draw_roi(frame, roi_vertices, color=(0, 0, 255))
        threading.Thread(target=play_beep, daemon=True).start()  # Start a new thread to play the beep sound
        
    elif low_proximity_flag:
        cv2.putText(frame, "Low Proximity", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        

    else:
        draw_roi(frame, roi_vertices)

    # draw_legend(frame)
    title = "Vehicle Proximity Alert"
    title_font = cv2.FONT_HERSHEY_SIMPLEX
    title_scale = 1
    title_thickness = 2
    title_color = (192, 192, 192)  # Light grey

    title_size = cv2.getTextSize(title, title_font, title_scale, title_thickness)
    title_width, title_height = title_size[0]
    title_x = (width - title_width) // 2
    title_y = 30

    # Draw a semi-transparent rectangle behind the text
    background_color = (0, 0, 0)
    background_alpha = 0.5
    background_margin = 10
    background_tl = (title_x - background_margin, title_y - title_height - background_margin)
    background_br = (title_x + title_width + background_margin, title_y + background_margin)
    overlay = frame.copy()
    cv2.rectangle(overlay, background_tl, background_br, background_color, -1)
    cv2.addWeighted(overlay, background_alpha, frame, 1 - background_alpha, 0, frame)

    # Draw the text on top of the rectangle
    text_position = (title_x, title_y)
    cv2.putText(frame, title, text_position, title_font, title_scale, title_color, title_thickness)

    cv2.imshow('Frame', frame)



    # Write the processed frame to the output video
    output_video.write(frame)

    # Press Q to quit the video
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

video.release()
#output_video.release()
cv2.destroyAllWindows()

end_time = time.time()

print("Processing time: {:.2f} seconds".format(end_time - start_time))
